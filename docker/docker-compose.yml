version: '3.8'

# SECURITY: All credentials MUST be set via environment variables.
# Copy .env.production.example to .env and fill in all values before starting.
# Services will fail to start if required credentials are missing.

services:
  postgres:
    image: postgres:16-alpine
    container_name: vizora-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:?Set POSTGRES_USER in .env}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?Set POSTGRES_PASSWORD in .env}
      POSTGRES_DB: vizora
    ports:
      - "127.0.0.1:5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
    networks:
      - vizora-network

  mongodb:
    image: mongo:7
    container_name: vizora-mongodb
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USERNAME:?Set MONGO_USERNAME in .env}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD:?Set MONGO_PASSWORD in .env}
    ports:
      - "127.0.0.1:27017:27017"
    volumes:
      - mongodb_data:/data/db
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
    networks:
      - vizora-network

  redis:
    image: redis:7-alpine
    container_name: vizora-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:?Set REDIS_PASSWORD in .env}
    ports:
      - "127.0.0.1:6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:?Set REDIS_PASSWORD in .env}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
    networks:
      - vizora-network

  minio:
    image: minio/minio:RELEASE.2024-06-13T22-53-53Z
    container_name: vizora-minio
    restart: unless-stopped
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:?Set MINIO_ROOT_USER in .env}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:?Set MINIO_ROOT_PASSWORD in .env}
    ports:
      - "127.0.0.1:9000:9000"
      - "127.0.0.1:9001:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
    networks:
      - vizora-network

  clickhouse:
    image: clickhouse/clickhouse-server:24
    container_name: vizora-clickhouse
    restart: unless-stopped
    ports:
      - "127.0.0.1:8123:8123"
      - "127.0.0.1:9002:9000"
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./clickhouse/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD", "clickhouse-client", "--query", "SELECT 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 2G
    networks:
      - vizora-network

  grafana:
    image: grafana/grafana:11.0.0
    container_name: vizora-grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:?Set GRAFANA_ADMIN_USER in .env}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:?Set GRAFANA_ADMIN_PASSWORD in .env}
      GF_INSTALL_PLUGINS: grafana-clickhouse-datasource
    ports:
      - "127.0.0.1:3003:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      clickhouse:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 512M
    networks:
      - vizora-network

  prometheus:
    image: prom/prometheus:v2.51.0
    container_name: vizora-prometheus
    restart: unless-stopped
    ports:
      - "127.0.0.1:9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=30d'
    deploy:
      resources:
        limits:
          memory: 512M
    networks:
      - vizora-network

  # ---------------------------------------------------------------------------
  # Application Service Scaling Strategy
  # ---------------------------------------------------------------------------
  # Middleware API and Web Dashboard can be horizontally scaled behind Nginx.
  # Realtime Gateway MUST stay single-instance for WebSocket state consistency.
  #
  # To scale when services are containerized (instead of host PM2), set
  # deploy.replicas on middleware and web services and use Docker service
  # names in the upstream blocks of nginx.conf.
  #
  # Example (add to a containerized middleware service):
  #   deploy:
  #     replicas: 2
  #     resources:
  #       limits:
  #         memory: 512M
  #
  # Example (add to a containerized web service):
  #   deploy:
  #     replicas: 2
  #     resources:
  #       limits:
  #         memory: 512M
  #
  # Realtime gateway — do NOT scale beyond 1 replica:
  #   deploy:
  #     replicas: 1
  # ---------------------------------------------------------------------------

  # ---------------------------------------------------------------------------
  # Nginx Reverse Proxy — TLS termination for all Vizora services
  # ---------------------------------------------------------------------------
  # The application services (middleware, web, realtime) run on the host via PM2.
  # Nginx proxies external HTTPS traffic to them.
  #
  # INITIAL SETUP: Generate SSL certificates before starting this service:
  #   ./scripts/setup-ssl.sh your-domain.com
  #
  # On Linux hosts, uncomment extra_hosts below so host.docker.internal resolves.
  nginx:
    profiles: ["production"]
    build:
      context: ./nginx
      dockerfile: Dockerfile
    # container_name omitted — required for deploy.replicas > 1
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - /etc/letsencrypt:/etc/letsencrypt:ro
      - certbot_webroot:/var/www/certbot:ro
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:80/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    # extra_hosts:
    #   - "host.docker.internal:host-gateway"  # Uncomment on Linux
    # In production, deploy behind an external load balancer (cloud ALB/NLB)
    # which distributes traffic across the replicas. The host port binding
    # below is for local development; with replicas > 1 Docker Compose will
    # warn in non-swarm mode but a single-node dev setup still works.
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 256M
    networks:
      - vizora-network

  # ---------------------------------------------------------------------------
  # Log Aggregation — Loki + Promtail
  # ---------------------------------------------------------------------------
  loki:
    image: grafana/loki:2.9.0
    container_name: vizora-loki
    restart: unless-stopped
    ports:
      - "127.0.0.1:3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    deploy:
      resources:
        limits:
          memory: 512M
    networks:
      - vizora-network

  promtail:
    image: grafana/promtail:2.9.0
    container_name: vizora-promtail
    restart: unless-stopped
    volumes:
      - ./promtail/promtail-config.yml:/etc/promtail/config.yml:ro
      - /var/log:/var/log:ro
      - ../logs:/app/logs:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    deploy:
      resources:
        limits:
          memory: 256M
    networks:
      - vizora-network

volumes:
  postgres_data:
    driver: local
  mongodb_data:
    driver: local
  redis_data:
    driver: local
  minio_data:
    driver: local
  clickhouse_data:
    driver: local
  grafana_data:
    driver: local
  certbot_webroot:
    driver: local
  prometheus_data:
    driver: local

networks:
  vizora-network:
    driver: bridge
